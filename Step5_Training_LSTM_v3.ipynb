{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "65c0ef24-f0fb-4cd4-a1f2-fe06bbb11ad7",
   "metadata": {},
   "source": [
    "# Step 1 | Platform SetupÂ¶"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8929564-6256-4660-9f31-922d3bae5223",
   "metadata": {},
   "source": [
    "## Step 1.1 | Check Environment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4c668d5-7051-4a22-a48a-e6e28ba04cd6",
   "metadata": {},
   "source": [
    "1. Open Anaconda Prompt\n",
    "2. conda activate tf-gpu\n",
    "3. cd \"C:\\Users\\FaithanTo\\Desktop\\MSBA 6421 (001) Predictive Analytics\\m5-forecasting-accuracy\"\n",
    "4. jupyter notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "23f88bd9-d67e-4bc0-8368-3ce73758e93f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda\\envs\\tf-gpu\\python.exe\n",
      "C:\\Anaconda\\python.exe\n"
     ]
    }
   ],
   "source": [
    "!where python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7563f958-b98c-410e-ae03-d07ee0ca7d7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda\\envs\\tf-gpu\\python.exe\n",
      "2.10.0\n",
      "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n",
      "1.13.1+cu116\n",
      "True\n",
      "NVIDIA GeForce RTX 3050 4GB Laptop GPU\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import tensorflow as tf\n",
    "import torch\n",
    "\n",
    "print(sys.executable)\n",
    "print(tf.__version__)\n",
    "print(tf.config.list_physical_devices('GPU'))\n",
    "print(torch.__version__)\n",
    "print(torch.cuda.is_available())\n",
    "print(torch.cuda.get_device_name(0))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54f809f3-9b4e-4a72-8969-d03aaa06613c",
   "metadata": {},
   "source": [
    "## Step 1.2 | Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "899ca49f-66b0-4d19-8196-cec9453c2c6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import polars as pl\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "import gc\n",
    "import warnings\n",
    "import os\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader, TensorDataset\n",
    "import torch.nn as nn\n",
    "from torch.optim import Adam\n",
    "from tqdm import tqdm\n",
    "from multiprocess import Pool, cpu_count\n",
    "from concurrent.futures import ProcessPoolExecutor, as_completed\n",
    "import multiprocessing\n",
    "import pickle\n",
    "import joblib\n",
    "import glob\n",
    "import psutil\n",
    "import os\n",
    "from m5_wrmsse import wrmsse\n",
    "import csv\n",
    "import concurrent.futures\n",
    "import threading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3e0338ef-c6b0-48cf-84ff-ebc796e24d68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NumPy version: 1.26.4\n"
     ]
    }
   ],
   "source": [
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"\"\n",
    "warnings.filterwarnings('ignore', category=FutureWarning)\n",
    "warnings.filterwarnings('ignore', category=RuntimeWarning)\n",
    "pd.set_option('display.max_columns', None)\n",
    "print(\"NumPy version:\", np.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce2005dd-0847-4092-98ec-2a5026b6b15b",
   "metadata": {},
   "source": [
    "# Step 2 | Training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bddcef23-7703-4e34-b786-c1d243faaf73",
   "metadata": {},
   "source": [
    "## Step 2.1 | Model Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "be0785c8-04aa-432a-8156-0b8f69e7a25c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === RMSE Loss ===\n",
    "class RMSELoss(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.mse = nn.MSELoss()\n",
    "\n",
    "    def forward(self, y_pred, y_true):\n",
    "        return torch.sqrt(self.mse(y_pred, y_true))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4b1f7430-ebdf-47e5-be39-e2fbeecf0fd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === LSTM Model with Embeddings ===\n",
    "class LSTMForecast(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers, output_len, \n",
    "                 item_vocab_size, dept_vocab_size, item_emb_dim=6, dept_emb_dim=3, dropout=0.4):\n",
    "        super(LSTMForecast, self).__init__()\n",
    "\n",
    "        # Embedding layers\n",
    "        self.item_emb = nn.Embedding(item_vocab_size, item_emb_dim)\n",
    "        self.dept_emb = nn.Embedding(dept_vocab_size, dept_emb_dim)\n",
    "\n",
    "        # Adjusted input size: original features + embedding dimensions (item_id + dept_id)\n",
    "        adjusted_input_size = input_size - 2 + item_emb_dim + dept_emb_dim\n",
    "\n",
    "        # LSTM layers\n",
    "        self.lstm = nn.LSTM(adjusted_input_size, hidden_size, num_layers, batch_first=True, dropout=dropout)\n",
    "\n",
    "        # Fully connected layers\n",
    "        self.fc1 = nn.Linear(hidden_size, 128)\n",
    "        self.leaky_relu = nn.LeakyReLU(negative_slope=0.01)\n",
    "        self.fc2 = nn.Linear(128, output_len)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Expecting item_id (x[:,:,0]) and dept_id (x[:,:,1]) as first two columns\n",
    "        item_ids = x[:, :, 0].long()\n",
    "        dept_ids = x[:, :, 1].long()\n",
    "\n",
    "        # Embed and concatenate with the rest of the features\n",
    "        item_embedded = self.item_emb(item_ids)\n",
    "        dept_embedded = self.dept_emb(dept_ids)\n",
    "        other_feats = x[:, :, 2:]  # everything except item_id and dept_id\n",
    "\n",
    "        # Concatenate along the last feature axis\n",
    "        x_combined = torch.cat([item_embedded, dept_embedded, other_feats], dim=2)\n",
    "\n",
    "        # LSTM and feedforward path\n",
    "        lstm_out, _ = self.lstm(x_combined)\n",
    "        last_hidden = lstm_out[:, -1, :]\n",
    "        x = self.fc1(last_hidden)\n",
    "        x = self.leaky_relu(x)\n",
    "        out = self.fc2(x)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5bdf840a-1396-4e1e-a92a-961542c00d19",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "25708c99-3a0f-4f60-aec2-d8a35e7ee7c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LSTMForecast(\n",
    "    input_size=29,  # assuming 29 original features\n",
    "    hidden_size=128,\n",
    "    num_layers=3,\n",
    "    output_len=28,\n",
    "    item_vocab_size=3049,\n",
    "    dept_vocab_size=7,\n",
    "    item_emb_dim=6,\n",
    "    dept_emb_dim=3,\n",
    "    dropout=0.4\n",
    ").to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "59c216cc-455b-4a67-9313-c8db1226b4b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Optimizer ===\n",
    "learning_rate = 0.0005  # You can adjust this as needed\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9450a8cc-36a7-4255-856a-96fe46a72745",
   "metadata": {},
   "source": [
    "## Step 2.2 | Load Data (Streaming Method)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ea9a6d7b-f9aa-44a6-afb6-2b5605eaafc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === 1. Load a Single Training Batch ===\n",
    "def load_batch(batch_dir, batch_idx):\n",
    "    \"\"\"\n",
    "    Loads a single training batch (X, y) from disk, with file existence checks.\n",
    "\n",
    "    Args:\n",
    "        batch_dir (str): Directory containing batch .npy files\n",
    "        batch_idx (int): Index of the batch to load\n",
    "\n",
    "    Returns:\n",
    "        Tuple of torch.FloatTensors: (X_tensor, y_tensor)\n",
    "    \"\"\"\n",
    "    X_path = os.path.join(batch_dir, f\"X_batch_{batch_idx}.npy\")\n",
    "    y_path = os.path.join(batch_dir, f\"Y_batch_{batch_idx}.npy\")\n",
    "\n",
    "    if not os.path.exists(X_path) or not os.path.exists(y_path):\n",
    "        raise FileNotFoundError(f\"Missing batch files: {X_path} or {y_path}\")\n",
    "\n",
    "    X = np.load(X_path)\n",
    "    y = np.load(y_path)\n",
    "\n",
    "    X_tensor = torch.from_numpy(X).float()\n",
    "    y_tensor = torch.from_numpy(y).float()\n",
    "\n",
    "    return X_tensor, y_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f57fe7f8-a23e-43e5-b708-dc8e859a024c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === 2. Wrap (X, y) into a DataLoader ===\n",
    "def make_dataloader(X_tensor, y_tensor, batch_size):\n",
    "    \"\"\"\n",
    "    Wraps X and y tensors into a PyTorch DataLoader with no shuffling.\n",
    "\n",
    "    Args:\n",
    "        X_tensor (Tensor): Feature tensor\n",
    "        y_tensor (Tensor): Target tensor\n",
    "        batch_size (int): Batch size for DataLoader\n",
    "\n",
    "    Returns:\n",
    "        DataLoader: PyTorch DataLoader object\n",
    "    \"\"\"\n",
    "    dataset = TensorDataset(X_tensor, y_tensor)\n",
    "    loader = DataLoader(dataset, \n",
    "                        batch_size=batch_size, \n",
    "                        shuffle=True, \n",
    "                        num_workers=4,\n",
    "                        pin_memory=True)\n",
    "    return loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "baa8d8d5-f255-48c8-8a4d-412deafd0f79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === 3. Load and Wrap Validation Set ===\n",
    "def get_val_loader(val_dir, batch_size):\n",
    "    \"\"\"\n",
    "    Loads full validation set and wraps it in a DataLoader with pin_memory.\n",
    "\n",
    "    Args:\n",
    "        val_dir (str): Directory containing validation .npy files\n",
    "        batch_size (int): Batch size for validation DataLoader\n",
    "\n",
    "    Returns:\n",
    "        DataLoader: PyTorch DataLoader for validation\n",
    "    \"\"\"\n",
    "    X_path = os.path.join(val_dir, \"X_val_final.npy\")\n",
    "    y_path = os.path.join(val_dir, \"y_val_final.npy\")\n",
    "\n",
    "    if not os.path.exists(X_path) or not os.path.exists(y_path):\n",
    "        raise FileNotFoundError(f\"Missing validation files: {X_path} or {y_path}\")\n",
    "\n",
    "    X_val = np.load(X_path)\n",
    "    y_val = np.load(y_path)\n",
    "\n",
    "    X_tensor = torch.from_numpy(X_val).float()\n",
    "    y_tensor = torch.from_numpy(y_val).float()\n",
    "\n",
    "    val_dataset = TensorDataset(X_tensor, y_tensor)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, pin_memory=True)\n",
    "    return val_loader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e444d97-e614-4fe1-8756-34b8fb16df7e",
   "metadata": {},
   "source": [
    "## Step 2.3 | Training Loop (Subfunctions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0fec1f18-39ed-4ffc-bf36-26f829209a63",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_epoch_metrics(log_path, epoch, train_loss, val_loss):\n",
    "    \"\"\"Appends one row to the CSV log file.\"\"\"\n",
    "    file_exists = os.path.exists(log_path)\n",
    "    with open(log_path, mode='a', newline='') as f:\n",
    "        writer = csv.writer(f)\n",
    "        if not file_exists:\n",
    "            writer.writerow([\"epoch\", \"avg_train_loss\", \"avg_val_loss\"])\n",
    "        writer.writerow([epoch, train_loss, val_loss])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "22bc9622-905f-4355-be10-f522204e43ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_loss_curve(history, plot_path):\n",
    "    \"\"\"Plots and saves train/val loss curves from history list.\"\"\"\n",
    "    epochs = [e for e, _, _ in history]\n",
    "    train_losses = [t for _, t, _ in history]\n",
    "    val_losses = [v for _, _, v in history]\n",
    "\n",
    "    plt.figure()\n",
    "    plt.plot(epochs, train_losses, label=\"Train RMSE\")\n",
    "    plt.plot(epochs, val_losses, label=\"Val RMSE\")\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.ylabel(\"RMSE Loss\")\n",
    "    plt.title(\"Training vs. Validation Loss\")\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.savefig(plot_path)\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6a2499d2-12ce-44d2-9f4a-40715f6646c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_model_checkpoint(model, optimizer, epoch, loss, path):\n",
    "    \"\"\"Saves model, optimizer, and metadata.\"\"\"\n",
    "    checkpoint = {\n",
    "        'epoch': epoch,\n",
    "        'model_state_dict': model.state_dict(),\n",
    "        'optimizer_state_dict': optimizer.state_dict(),\n",
    "        'val_loss': loss\n",
    "    }\n",
    "    torch.save(checkpoint, path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "23fa654c-9c0f-446e-b294-096bd53c1c44",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AsyncBatchLoader:\n",
    "    def __init__(self, batch_dir, total_batches, preload_ahead=1):\n",
    "        self.batch_dir = batch_dir\n",
    "        self.total_batches = total_batches\n",
    "        self.executor = concurrent.futures.ThreadPoolExecutor(max_workers=1)\n",
    "        self.preload_ahead = preload_ahead\n",
    "        self.lock = threading.Lock()\n",
    "\n",
    "        self._current_idx = 0\n",
    "        self._future = None\n",
    "\n",
    "    def _load_next(self, idx):\n",
    "        return load_batch(self.batch_dir, idx)\n",
    "\n",
    "    def get_next_batch(self):\n",
    "        with self.lock:\n",
    "            if self._future is None:\n",
    "                self._future = self.executor.submit(self._load_next, self._current_idx)\n",
    "\n",
    "            X, y = self._future.result()\n",
    "\n",
    "            self._current_idx += 1\n",
    "            if self._current_idx < self.total_batches:\n",
    "                self._future = self.executor.submit(self._load_next, self._current_idx)\n",
    "            else:\n",
    "                self._future = None\n",
    "\n",
    "            return X, y\n",
    "\n",
    "    def done(self):\n",
    "        return self._current_idx >= self.total_batches"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c873c888-1056-4026-bf0d-47be6754ef9a",
   "metadata": {},
   "source": [
    "## Step 2.4 | Training Loop (Main)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "76c16148-337c-4cc1-8178-2066d4562114",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a2b5c6a8-0728-4d67-ad2b-891aa5ccf0d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_training_environment(model, optimizer, resume_path, device):\n",
    "    start_epoch = 1\n",
    "    best_val_loss = float(\"inf\")\n",
    "    \n",
    "    if resume_path and os.path.exists(resume_path):\n",
    "        print(f\"ð Resuming from checkpoint: {resume_path}\")\n",
    "        checkpoint = torch.load(resume_path, map_location=device)\n",
    "        model.load_state_dict(checkpoint['model_state_dict'])\n",
    "        optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "        start_epoch = checkpoint['epoch'] + 1\n",
    "        best_val_loss = checkpoint.get('val_loss', float(\"inf\"))\n",
    "\n",
    "    return model.to(device), optimizer, start_epoch, best_val_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3bf968b2-1dba-44d9-b358-a47ddea1ea20",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_randomized_batches(group_dir, seed=42):\n",
    "    all_ids = sorted([\n",
    "        int(f.replace(\"X_batch_\", \"\").replace(\".npy\", \"\"))\n",
    "        for f in os.listdir(group_dir)\n",
    "        if f.startswith(\"X_batch_\") and f.endswith(\".npy\")\n",
    "    ])\n",
    "    random.seed(seed)\n",
    "    random.shuffle(all_ids)\n",
    "    return all_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "cbcc482b-6c98-4c8c-891a-3af1081d5fed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_on_batch(model, train_loader, criterion, optimizer, device):\n",
    "    total_loss = 0.0\n",
    "\n",
    "    for X_batch, y_batch in train_loader:\n",
    "        X_batch = X_batch.to(device)\n",
    "        y_batch = y_batch.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        output = model(X_batch)\n",
    "        \n",
    "        # === Loss weighting based on is_new_id ===\n",
    "        with torch.no_grad():\n",
    "            is_new_id_mask = X_batch[:, :, input_cols.index(\"is_new_id\")]\n",
    "            weights = torch.where(is_new_id_mask == 1, 0.25, 1.0)\n",
    "        \n",
    "        # Compute unweighted loss\n",
    "        squared_errors = (output - y_batch) ** 2\n",
    "        \n",
    "        # Apply weights and compute weighted RMSE\n",
    "        weighted_mse = (weights * squared_errors).mean()\n",
    "        loss = torch.sqrt(weighted_mse)\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "    \n",
    "    return total_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ec31e084-e1f8-445a-ae62-2d3cab825e45",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, val_loader, criterion, device):\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    with torch.no_grad():\n",
    "        for X_val, y_val in val_loader:\n",
    "            X_val = X_val.to(device)\n",
    "            y_val = y_val.to(device)\n",
    "            val_preds = model(X_val)\n",
    "            loss = criterion(val_preds, y_val)\n",
    "            val_loss += loss.item()\n",
    "    return val_loss / len(val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2b7b8d5b-2daa-478b-9ab4-dd59bc4d9bee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_and_save(epoch, train_loss, val_loss, history, model, optimizer, checkpoint_path, save_best_path, log_path, best_val_loss):\n",
    "    history.append((epoch, train_loss, val_loss))\n",
    "    save_epoch_metrics(log_path, epoch, train_loss, val_loss)\n",
    "    save_model_checkpoint(model, optimizer, epoch, val_loss, checkpoint_path)\n",
    "\n",
    "    if val_loss < best_val_loss:\n",
    "        print(f\"ð¾ New best model! ({best_val_loss:.4f} â {val_loss:.4f})\")\n",
    "        best_val_loss = val_loss\n",
    "        torch.save(model.state_dict(), save_best_path)\n",
    "    \n",
    "    return best_val_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b4e9438a-deba-4a33-a014-3225a8910e38",
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_debug_stats(epoch, batch_idx, y, val_loader, output=None, y_batch=None):\n",
    "    if epoch == 1 and batch_idx == 0:\n",
    "        print(\"ð Train y sample stats â\")\n",
    "        print(\"  Min:\", y.min().item(), \"Max:\", y.max().item(), \"Mean:\", y.mean().item())\n",
    "\n",
    "        X_val_sample, y_val_sample = next(iter(val_loader))\n",
    "        print(\"ð Val y sample stats â\")\n",
    "        print(\"  Min:\", y_val_sample.min().item(), \n",
    "              \"Max:\", y_val_sample.max().item(), \n",
    "              \"Mean:\", y_val_sample.mean().item())\n",
    "\n",
    "    if output is not None and y_batch is not None:\n",
    "        preds = output.detach().cpu().numpy()\n",
    "        targets = y_batch.detach().cpu().numpy()\n",
    "        batch_rmse = np.sqrt(np.mean((preds - targets) ** 2))\n",
    "        print(f\"\\nð¬ Full batch RMSE: {batch_rmse:.4f}\")\n",
    "        print(f\"Batch target stats â Min: {targets.min()}, Max: {targets.max()}, Mean: {targets.mean():.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "553a29d4-05eb-454b-a845-9e5c5440bf41",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clear_batch_from_memory(*args):\n",
    "    for var in args:\n",
    "        del var\n",
    "    gc.collect()\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ca67d3d7-345a-4cba-b848-ed3b5b071258",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_lstm_v3(\n",
    "    model,\n",
    "    train_dir,\n",
    "    val_dir,\n",
    "    num_epochs,\n",
    "    total_batches,\n",
    "    batch_size,\n",
    "    save_best_path,\n",
    "    checkpoint_path,\n",
    "    log_path,\n",
    "    plot_path,\n",
    "    device=torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\"),\n",
    "    resume_path=None,\n",
    "    validate_every=1,  # how often to run validation (in epochs)\n",
    "):\n",
    "\n",
    "    print(\"ð Starting training...\")\n",
    "    model = model.to(device)\n",
    "    criterion = nn.MSELoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "    train_losses = []\n",
    "    val_losses = []\n",
    "    best_val_loss = float(\"inf\")\n",
    "\n",
    "    # === PRELOAD BATCH GROUPS ONCE ===\n",
    "    batch_groups = get_randomized_batches(train_dir)\n",
    "    assert len(batch_groups) == total_batches, f\"Expected {total_batches} batches but got {len(batch_groups)}\"\n",
    "\n",
    "    # === LOAD VALIDATION SET ONCE ===\n",
    "    X_val = np.load(os.path.join(val_dir, \"X_val_final.npy\"))\n",
    "    y_val = np.load(os.path.join(val_dir, \"y_val_final.npy\"))\n",
    "\n",
    "    X_tensor = torch.tensor(X_batch, dtype=torch.float32)\n",
    "    y_tensor = torch.tensor(y_batch, dtype=torch.float32)\n",
    "    \n",
    "    train_loader = make_dataloader(X_tensor, y_tensor, batch_size=32)\n",
    "    \n",
    "    for X_mini, y_mini in train_loader:\n",
    "        X_mini = X_mini.to(device, non_blocking=True)\n",
    "        y_mini = y_mini.to(device, non_blocking=True)\n",
    "    \n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(X_mini)\n",
    "        loss = criterion(outputs, y_mini)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "        epoch_loss += loss.item()\n",
    "    \n",
    "        del X_mini, y_mini, outputs\n",
    "        torch.cuda.empty_cache()\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        epoch_loss = 0.0\n",
    "        start_time = time.time()\n",
    "\n",
    "        for i in batch_groups:\n",
    "            X_batch = np.load(os.path.join(train_dir, f\"X_batch_{i}.npy\"))\n",
    "            y_batch = np.load(os.path.join(train_dir, f\"Y_batch_{i}.npy\"))\n",
    "        \n",
    "            X_tensor = torch.tensor(X_batch, dtype=torch.float32)\n",
    "            y_tensor = torch.tensor(y_batch, dtype=torch.float32)\n",
    "        \n",
    "            X_tensor = X_tensor.to(device, non_blocking=True)\n",
    "            y_tensor = y_tensor.to(device, non_blocking=True)\n",
    "        \n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(X_tensor)\n",
    "            loss = criterion(outputs, y_tensor)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        \n",
    "            epoch_loss += loss.item()\n",
    "        \n",
    "            # â Explicitly clear memory\n",
    "            del X_tensor, y_tensor, outputs\n",
    "            torch.cuda.empty_cache()\n",
    "\n",
    "        avg_epoch_loss = epoch_loss / total_batches\n",
    "        train_losses.append(avg_epoch_loss)\n",
    "\n",
    "        # === Optional Validation ===\n",
    "        if (epoch + 1) % validate_every == 0:\n",
    "            model.eval()\n",
    "            with torch.no_grad():\n",
    "                val_outputs = model(X_val_tensor)\n",
    "                val_loss = criterion(val_outputs, y_val_tensor).item()\n",
    "                val_losses.append(val_loss)\n",
    "        else:\n",
    "            val_loss = None\n",
    "\n",
    "        # === Save Best Model ===\n",
    "        if val_loss is not None and val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "            torch.save(model.state_dict(), save_best_path)\n",
    "\n",
    "        # === Save Checkpoint ===\n",
    "        torch.save(model.state_dict(), checkpoint_path)\n",
    "\n",
    "        # === Logging ===\n",
    "        log_metrics_to_csv(log_path, epoch + 1, avg_epoch_loss, val_loss)\n",
    "        print(f\"â Epoch {epoch+1}/{num_epochs} - Train Loss: {avg_epoch_loss:.4f} - Val Loss: {val_loss:.4f if val_loss else 'Skipped'} - Time: {time.time() - start_time:.1f}s\")\n",
    "\n",
    "    # === Plot Loss Curves ===\n",
    "    plot_loss_curves(train_losses, val_losses, save_path=plot_path)\n",
    "    print(\"ð Training complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "eaf54b48-53b4-453e-9d85-0c06e3002558",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "692e3b74-a817-4141-8a50-820ad080872b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# === Run training ===\n",
    "train_lstm_v3(\n",
    "    model=model,\n",
    "    train_dir=\"sequence_chunks_v3\",        # training data batches\n",
    "    val_dir=\"val_sequences_polars\",         # validation sequences\n",
    "    num_epochs=5,\n",
    "    total_batches=305,\n",
    "    batch_size=32,\n",
    "    save_best_path=\"best_model_lstm_v3.pth\",\n",
    "    checkpoint_path=\"model_latest.pth\",\n",
    "    log_path=\"metrics_lstm_v3.csv\",\n",
    "    plot_path=\"loss_plot_lstm_v3.png\",\n",
    "    resume_path=\"model_latest.pth\"         # or None to start from scratch\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be44b869-fba4-4486-b268-0ade8bd44e7b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1656113f-0cb5-439c-8acf-f602a323214f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6f912dfe-cdbc-4d4f-a1b0-8cb4789a9a52",
   "metadata": {},
   "source": [
    "# OLD CODE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "5f29897e-28c1-443b-a73e-57f81f64c958",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_lstm_v3(\n",
    "    model, \n",
    "    train_dir, \n",
    "    val_dir, \n",
    "    num_epochs=5, \n",
    "    total_batches=305, \n",
    "    batch_size=32,\n",
    "    save_best_path=\"best_model_lstm_v3.pth\",\n",
    "    checkpoint_path=\"model_latest.pth\",\n",
    "    log_path=\"metrics_lstm_v3.csv\",\n",
    "    plot_path=\"loss_plot_lstm_v3.png\",\n",
    "    resume_path=None  # Optional: resume from checkpoint\n",
    "):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    print(f\"ð¦ Training on device: {device}\")\n",
    "    model.to(device)\n",
    "\n",
    "    criterion = RMSELoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.0005)\n",
    "    val_loader = get_val_loader(val_dir, batch_size=batch_size)\n",
    "\n",
    "    best_val_loss = float(\"inf\")\n",
    "    start_epoch = 1\n",
    "    history = []\n",
    "\n",
    "    # === Resume logic ===\n",
    "    if resume_path and os.path.exists(resume_path):\n",
    "        print(f\"ð Resuming from checkpoint: {resume_path}\")\n",
    "        checkpoint = torch.load(resume_path, map_location=device)\n",
    "        model.load_state_dict(checkpoint['model_state_dict'])\n",
    "        optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "        start_epoch = checkpoint['epoch'] + 1\n",
    "        best_val_loss = checkpoint.get('val_loss', float(\"inf\"))\n",
    "\n",
    "    async_loader = AsyncBatchLoader(train_dir, total_batches)\n",
    "\n",
    "    for epoch in range(start_epoch, num_epochs + 1):\n",
    "        async_loader._current_idx = 0\n",
    "\n",
    "        model.train()\n",
    "        epoch_train_loss = 0.0\n",
    "        print(f\"\\nð Epoch {epoch}/{num_epochs}\")\n",
    "\n",
    "        for batch_idx in tqdm(range(total_batches), desc=f\"Epoch {epoch}\"):\n",
    "            try:\n",
    "                X, y = async_loader.get_next_batch()\n",
    "            except FileNotFoundError as e:\n",
    "                print(f\"â ï¸ Skipping batch: {e}\")\n",
    "                continue\n",
    "\n",
    "            # if epoch == start_epoch and batch_idx == 0:\n",
    "            #     # Log training target stats\n",
    "            #     print(\"ð Train y sample stats â\")\n",
    "            #     print(\"  Min:\", y.min().item(), \n",
    "            #           \"Max:\", y.max().item(), \n",
    "            #           \"Mean:\", y.mean().item())\n",
    "\n",
    "            #     # Log validation target stats\n",
    "            #     X_val_sample, y_val_sample = next(iter(val_loader))\n",
    "            #     print(\"ð Val y sample stats â\")\n",
    "            #     print(\"  Min:\", y_val_sample.min().item(), \n",
    "            #           \"Max:\", y_val_sample.max().item(), \n",
    "            #           \"Mean:\", y_val_sample.mean().item())\n",
    "            \n",
    "            train_loader = make_dataloader(X, y, batch_size)\n",
    "            for X_batch, y_batch in train_loader:\n",
    "                \n",
    "                # print(f\"â¡ï¸ y_batch mean: {y_batch.mean().item():.4f}\")\n",
    "    \n",
    "                X_batch = X_batch.to(device)\n",
    "                y_batch = y_batch.to(device)\n",
    "        \n",
    "                optimizer.zero_grad()\n",
    "                output = model(X_batch)\n",
    "                loss = criterion(output, y_batch)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                epoch_train_loss += loss.item()\n",
    "\n",
    "\n",
    "                \n",
    "                # if epoch == start_epoch and batch_idx == 0:\n",
    "                #     preds = output.detach().cpu().numpy()\n",
    "                #     targets = y_batch.detach().cpu().numpy()\n",
    "                #     batch_rmse = np.sqrt(np.mean((preds - targets)**2))\n",
    "                #     print(f\"\\nð¬ Full batch RMSE: {batch_rmse:.4f}\")\n",
    "                #     print(f\"Batch target stats â Min: {targets.min()}, Max: {targets.max()}, Mean: {targets.mean():.4f}\")\n",
    "\n",
    "\n",
    "        \n",
    "            # ð® Clear batch from memory\n",
    "            del X, y, train_loader, X_batch, y_batch, output, loss\n",
    "            gc.collect()\n",
    "            if torch.cuda.is_available():\n",
    "                torch.cuda.empty_cache()\n",
    "        \n",
    "        avg_train_loss = epoch_train_loss / total_batches\n",
    "        print(f\"ð Avg Train Loss: {avg_train_loss:.4f}\")\n",
    "\n",
    "        # === Validation ===\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for X_val, y_val in val_loader:\n",
    "                X_val = X_val.to(device)\n",
    "                y_val = y_val.to(device)\n",
    "                val_preds = model(X_val)\n",
    "                loss = criterion(val_preds, y_val)\n",
    "                val_loss += loss.item()\n",
    "        avg_val_loss = val_loss / len(val_loader)\n",
    "        print(f\"ð§ª Validation Loss: {avg_val_loss:.4f}\")\n",
    "\n",
    "        # === Save Metrics, Plot, and Checkpoints ===\n",
    "        history.append((epoch, avg_train_loss, avg_val_loss))\n",
    "        save_epoch_metrics(log_path, epoch, avg_train_loss, avg_val_loss)\n",
    "        save_model_checkpoint(model, optimizer, epoch, avg_val_loss, checkpoint_path)\n",
    "\n",
    "        if avg_val_loss < best_val_loss:\n",
    "            print(f\"ð¾ New best model! ({best_val_loss:.4f} â {avg_val_loss:.4f})\")\n",
    "            best_val_loss = avg_val_loss\n",
    "            torch.save(model.state_dict(), save_best_path)\n",
    "\n",
    "    async_loader.executor.shutdown(wait=True)\n",
    "\n",
    "    # === Final loss plot ===\n",
    "    plot_loss_curve(history, plot_path)\n",
    "    print(f\"ð Loss plot saved to {plot_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b575b916-ef19-4a91-b9de-aafc0504c3e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_lstm_v3(\n",
    "    model,\n",
    "    train_dir=\"sequence_chunks_v3\",\n",
    "    val_dir=\"val_sequences_polars\",\n",
    "    num_epochs=5,\n",
    "    total_batches=305,\n",
    "    resume_path=\"model_latest.pth\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd3dbb27-3431-43a4-926e-a7fccdcfbfa7",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "9e7fe7b8-3b19-4cc8-abc3-e212bf3a55e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LSTMForecast(\n",
    "    input_size=29,  # assuming 29 original features\n",
    "    hidden_size=128,\n",
    "    num_layers=3,\n",
    "    output_len=28,\n",
    "    item_vocab_size=3049,\n",
    "    dept_vocab_size=7,\n",
    "    item_emb_dim=6,\n",
    "    dept_emb_dim=3,\n",
    "    dropout=0.4\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "9e0fe170-498b-4ecd-8cfc-43434b6f5c07",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LSTMForecast(\n",
       "  (item_emb): Embedding(3049, 6)\n",
       "  (dept_emb): Embedding(7, 3)\n",
       "  (lstm): LSTM(36, 128, num_layers=3, batch_first=True, dropout=0.4)\n",
       "  (fc1): Linear(in_features=128, out_features=128, bias=True)\n",
       "  (leaky_relu): LeakyReLU(negative_slope=0.01)\n",
       "  (fc2): Linear(in_features=128, out_features=28, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(torch.load(\"best_model_lstm_v3.pth\", map_location=torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")))\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "c5b6329f-849a-4526-bcf4-0790d6e80087",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LSTMForecast(\n",
       "  (item_emb): Embedding(3049, 6)\n",
       "  (dept_emb): Embedding(7, 3)\n",
       "  (lstm): LSTM(36, 128, num_layers=3, batch_first=True, dropout=0.4)\n",
       "  (fc1): Linear(in_features=128, out_features=128, bias=True)\n",
       "  (leaky_relu): LeakyReLU(negative_slope=0.01)\n",
       "  (fc2): Linear(in_features=128, out_features=28, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "e6636bd7-b0ed-4798-b7cb-5f4bbee9b808",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load 56-day input sequences and item IDs\n",
    "X_eval = np.load(\"eval_sequences_polars/X_eval_final.npy\")  # shape: (num_items, 56, num_features)\n",
    "ids = np.load(\"eval_sequences_polars/ids_eval_final.npy\", allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "c9c34c39-3385-4ba7-b4cd-a77a55f77562",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare batched DataLoader\n",
    "batch_size = 32  # or smaller if needed\n",
    "dataset = TensorDataset(torch.tensor(X_eval, dtype=torch.float32))\n",
    "loader = DataLoader(dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "model.eval()\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "# Run batched inference\n",
    "all_preds = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for (X_batch,) in loader:\n",
    "        X_batch = X_batch.to(device)\n",
    "        preds = model(X_batch).cpu().numpy()\n",
    "        all_preds.append(preds)\n",
    "\n",
    "y_pred = np.vstack(all_preds)  # shape: (num_items, 28)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "d63553fc-0420-4667-b200-378c47c4d947",
   "metadata": {},
   "outputs": [],
   "source": [
    "ids_eval = np.load(\"eval_sequences_polars/ids_eval_final.npy\", allow_pickle=True)\n",
    "df_eval = pd.DataFrame(y_pred, columns=[f\"F{i}\" for i in range(1, 29)])\n",
    "df_eval.insert(0, \"id\", ids_eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "05c23308-f862-4c72-ac2e-e27c675923e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "sales = pd.read_csv(\"Kaggle Files/sales_train_evaluation.csv\")\n",
    "val_cols = [f\"d_{d}\" for d in range(1914, 1942)]  # 28 days\n",
    "df_val = sales[[\"id\"] + val_cols].copy()\n",
    "\n",
    "# Rename to F1âF28 to match Kaggle format\n",
    "df_val.columns = [\"id\"] + [f\"F{i}\" for i in range(1, 29)]\n",
    "df_val[\"id\"] = df_val[\"id\"].str.replace(\"_evaluation\", \"_validation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "8f767cb2-5ed1-4867-ba85-f7cf6fc3c8b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.concat([df_val, df_eval], axis=0)\n",
    "submission.to_csv(\"submission.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "332be125-7aa5-4de9-bd69-296335a7d183",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (tf-gpu)",
   "language": "python",
   "name": "tf-gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
